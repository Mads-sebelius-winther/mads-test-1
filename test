import gym
from stable_baselines3 import PPO
import matplotlib.pyplot as plt
import numpy as np

# Create the BipedalWalker environment
env = gym.make('BipedalWalker-v3')

# Initialize the PPO model with a neural network policy
model = PPO("MlpPolicy", env, verbose=1)

# Train the model for 100,000 timesteps
model.learn(total_timesteps=100000)

# Save the trained model
model.save("ppo_bipedalwalker")

# Evaluate the trained model (run 10 episodes and calculate the average reward)
episodes = 10
all_rewards = []

for ep in range(episodes):
    obs = env.reset()
    done = False
    total_reward = 0

    while not done:
        action, _state = model.predict(obs, deterministic=True)
        obs, reward, done, _info = env.step(action)
        total_reward += reward
    
    all_rewards.append(total_reward)

# Print average reward
avg_reward = np.mean(all_rewards)
print(f"Average reward over {episodes} episodes: {avg_reward}")

# Close the environment
env.close()

# Optional: Plot the rewards per episode
plt.plot(range(episodes), all_rewards)
plt.title("Rewards per Episode")
plt.xlabel("Episode")
plt.ylabel("Reward")
plt.show()
